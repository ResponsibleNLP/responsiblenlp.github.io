@inproceedings{kesen-etal-2024vilma,
    title={Vi{LMA}: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models},
    author={Kesen, Ilker and
        Pedrotti, Andrea and
        Dogan, Mustafa and
        Cafagna, Michele and
        Acikgoz, Emre Can and
        Parcalabescu, Letitia and
        Calixto, Iacer and
        Frank, Anette and
        Gatt, Albert and
        Erdem, Aykut and
        Erdem Erkut},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=liuqDwmbQJ},
    bibtex_show = "",
    selected = "true",
    abbr = "ICLR",
    html = "https://openreview.net/forum?id=liuqDwmbQJ",
    preview = "ViLMA-Figure1.png",
}
@inproceedings{barreiro-etal-2022-multi3generation,
    title = "{M}ulti3{G}eneration: Multitask, Multilingual, Multimodal Language Generation",
    author = "Barreiro, Anabela  and
      de Souza, Jos{\'e} GC  and
      Gatt, Albert  and
      Bhatt, Mehul  and
      Lloret, Elena  and
      Erdem, Aykut  and
      Gkatzia, Dimitra  and
      Moniz, Helena  and
      Russo, Irene  and
      Kepler, Fabio  and
      Calixto, Iacer  and
      Paprzycki, Marcin  and
      Portet, Fran{\c{c}}ois  and
      Augenstein, Isabelle  and
      Alhasani, Mirela",
    booktitle = "Proceedings of the 23rd Annual Conference of the European Association for Machine Translation",
    month = jun,
    year = "2022",
    address = "Ghent, Belgium",
    publisher = "European Association for Machine Translation",
    url = "https://aclanthology.org/2022.eamt-1.63",
    pages = "347--348",
    abstract = "This paper presents the Multitask, Multilingual, Multimodal Language Generation COST Action {--} Multi3Generation (CA18231), an interdisciplinary network of research groups working on different aspects of language generation. This {``}meta-paper{''} will serve as reference for citations of the Action in future publications. It presents the objectives, challenges and a the links for the achieved outcomes.",
    bibtex_show = "",
    abbr = "EAMT",
    html = "https://aclanthology.org/2022.eamt-1.63/",
    preview = "Multi3Generation-logo-text-transparent.svg.png",
}
@article{10.1613/jair.1.12918,
author = {Erdem, Erkut and Kuyu, Menekse and Yagcioglu, Semih and Frank, Anette and Parcalabescu, Letitia and Plank, Barbara and Babii, Andrii and Turuta, Oleksii and Erdem, Aykut and Calixto, Iacer and Lloret, Elena and Apostol, Elena-Simona and Truic\u{a}, Ciprian-Octavian and \v{S}andrih, Branislava and Martin\v{c}i\'{c}-Ip\v{s}i\'{c}, Sanda and Berend, G\'{a}bor and Gatt, Albert and Korvel, Gr\u{a}zina},
title = {Neural Natural Language Generation: A Survey on Multilinguality, Multimodality, Controllability and Learning},
year = {2022},
issue_date = {May 2022},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {73},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.12918},
doi = {10.1613/jair.1.12918},
abstract = {Developing artificial learning systems that can understand and generate natural language has been one of the long-standing goals of artificial intelligence. Recent decades have witnessed an impressive progress on both of these problems, giving rise to a new family of approaches. Especially, the advances in deep learning over the past couple of years have led to neural approaches to natural language generation (NLG). These methods combine generative language learning techniques with neural-networks based frameworks. With a wide range of applications in natural language processing, neural NLG (NNLG) is a new and fast growing field of research. In this state-of-the-art report, we investigate the recent developments and applications of NNLG in its full extent from a multidimensional view, covering critical perspectives such as multimodality, multilinguality, controllability and learning strategies. We summarize the fundamental building blocks of NNLG approaches from these aspects and provide detailed reviews of commonly used preprocessing steps and basic neural architectures. This report also focuses on the seminal applications of these NNLG models such as machine translation, description generation, automatic speech recognition, abstractive summarization, text simplification, question answering and generation, and dialogue generation. Finally, we conclude with a thorough discussion of the described frameworks by pointing out some open research directions.},
journal = {J. Artif. Int. Res.},
month = {may},
numpages = {77},
bibtex_show = "",
alt_metric = "true", dimensions = "true",
abbr = "JAIR",
html = "https://www.jair.org/index.php/jair/article/view/12918",
preview = "NNLG_Figure1.png",
selected = "true",
keywords = {natural language, neural networks},
}
@article{huang2022endowing,
  title={Endowing language models with multimodal knowledge graph representations},
  author={Huang, Ningyuan and Deshpande, Yash R and Liu, Yibo and Alberts, Houda and Cho, Kyunghyun and Vania, Clara and Calixto, Iacer},
  journal={arXiv preprint arXiv:2206.13163},
  year={2022},
  bibtex_show = "",
  preview = "Endowing_Figure1.png",
  abbr = "Pre-print",
  arxiv = "2206.13163",
  code = "https://github.com/iacercalixto/visualsem-kg/",
  abstract={We propose a method to make natural language understanding models more parameter efficient by storing knowledge in an external knowledge graph (KG) and retrieving from this KG using a dense index. Given (possibly multilingual) downstream task data, e.g., sentences in German, we retrieve entities from the KG and use their multimodal representations to improve downstream task performance. We use the recently released VisualSem KG as our external knowledge repository, which covers a subset of Wikipedia and WordNet entities, and compare a mix of tuple-based and graph-based algorithms to learn entity and relation representations that are grounded on the KG multimodal information. We demonstrate the usefulness of the learned entity representations on two downstream tasks, and show improved performance on the multilingual named entity recognition task by 0.3%--0.7% F1, while we achieve up to 2.5% improvement in accuracy on the visual sense disambiguation task. All our code and data are available in: \url{this https URL}.}
}
@inproceedings{kesen-etal-2022-detecting,
    title = "Detecting Euphemisms with Literal Descriptions and Visual Imagery",
    author = "Kesen, Ilker  and
      Erdem, Aykut  and
      Erdem, Erkut  and
      Calixto, Iacer",
    booktitle = "Proceedings of the 3rd Workshop on Figurative Language Processing (FLP)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.flp-1.9",
    doi = "10.18653/v1/2022.flp-1.9",
    pages = "61--67",
    abstract = "This paper describes our two-stage system for the Euphemism Detection shared task hosted by the 3rd Workshop on Figurative Language Processing in conjunction with EMNLP 2022. Euphemisms tone down expressions about sensitive or unpleasant issues like addiction and death. The ambiguous nature of euphemistic words or expressions makes it challenging to detect their actual meaning within a context. In the first stage, we seek to mitigate this ambiguity by incorporating literal descriptions into input text prompts to our baseline model. It turns out that this kind of direct supervision yields remarkable performance improvement. In the second stage, we integrate visual supervision into our system using visual imageries, two sets of images generated by a text-to-image model by taking terms and descriptions as input. Our experiments demonstrate that visual supervision also gives a statistically significant performance boost. Our system achieved the second place with an F1 score of 87.2{\%}, only about 0.9{\%} worse than the best submission.",
    bibtex_show = "",
    html = "https://aclanthology.org/2022.flp-1.9/",
    abbr = "ACL Workshop",
    code = "https://github.com/ilkerkesen/euphemism",
    preview = "Detecting-euphemisms_Tab1.png",
}
@incollection{2436/624261,
  author      = {Calixto, Iacer and Yaneva, Viktoriya and Cardoso, Raphael},
  title       = {Natural language processing for mental disorders: an overview},
  publisher   = {CRC Press},
  editor      = "Dash, S.R., Parida, S., Tello, E.V., Acharya, B., and Bojar, O. ",
  booktitle   = "Natural Language Processing in Healthcare: A Special Focus on Low Resource Languages",
  year        = {2022},
  pages       = "37-59",
  isbn = {9780367685393},
  doi = {https://doi.org/10.1201/9781003138013},
  url = {http://hdl.handle.net/2436/624261},
  abstract = {
    In recent years, there has been a surge in interest in using natural language processing (NLP) applications for clinical psychology and psychiatry. Despite the increased societal, economic, and academic interest, there has been no systematic critical analysis of the recent progress in NLP applications for mental disorders, or of the resources available for training and evaluating such systems.

    This chapter addresses this gap through two main contributions. First, it provides an overview of the NLP literature related to mental disorders, with a focus on autism, dyslexia, schizophrenia, depression and mental health in general. We discuss the strengths and shortcomings of current methodologies, specifically focusing on the challenges in obtaining large volumes of high-quality domain-specific data both for English and for lower-resource languages. We also provide a list of datasets publicly available for researchers who would like to develop NLP methods for specific mental disorders, categorized according to relevant criteria such as data source, language, annotation, and size. Our second contribution is a discussion on how to support the application of these methods to various languages and social contexts. This includes recommendations on conducting robust and ethical experiments from a machine learning perspective, and a discussion on how techniques such as cross-lingual transfer learning could be applied within this area. },
  bibtex_show = "",
  abbr = "Book Chapter",
  selected = "true",
  html = "https://www.taylorfrancis.com/chapters/edit/10.1201/9781003138013-3/natural-language-processing-mental-disorders-overview-iacer-calixto-victoria-yaneva-raphael-moura-cardoso",
  preview = "NLP-for-mental-health_Fig1.png",
}
@ARTICLE{Brancato2023-le,
  title    = "Leveraging {Multi-Word} Concepts to Predict Acute Kidney Injury
              in Intensive Care",
  author   = "Brancato, Lorenzo and Calixto, Iacer and Abu-Hanna, Ameen and
              Vagliano, Iacopo",
  abstract = "Acute kidney injury (AKI) is an abrupt decrease in kidney
              function widespread in intensive care. Many AKI prediction models
              have been proposed, but only few exploit clinical notes and
              medical terminologies. Previously, we developed and internally
              validated a model to predict AKI using clinical notes enriched
              with single-word concepts from medical knowledge graphs. However,
              an analysis of the impact of using multi-word concepts is
              lacking. In this study, we compare the use of only the clinical
              notes as input to prediction to the use of clinical notes
              retrofitted with both single-word and multi-word concepts. Our
              results show that 1) retrofitting single-word concepts improved
              word representations and improved the performance of the
              prediction model; 2) retrofitting multi-word concepts further
              improves both results, albeit slightly. Although the improvement
              with multi-word concepts was small, due to the small number of
              multi-word concepts that could be annotated, multi-word concepts
              have proven to be beneficial.",
  journal  = "Stud Health Technol Inform",
  volume   =  305,
  pages    = "10--13",
  month    =  jun,
  year     =  2023,
  address  = "Netherlands",
  keywords = "Clinical Prediction; Knowledge Graphs; Natural Language
              Processing",
  language = "en",
  html     = "https://pubmed.ncbi.nlm.nih.gov/37386944/",
  bibtex_show = "",
  note     = "Best paper award",
}
@InProceedings{Zonneveld_2023_ICCV,
    author    = {Zonneveld, Anne and Gatt, Albert and Calixto, Iacer},
    title     = {Video-and-Language (VidL) models and their cognitive relevance},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},
    month     = {October},
    year      = {2023},
    pages     = {325-338},
    abstract  = {In this paper we give a narrative review of multi-modal video-language (VidL) models. We introduce the current landscape of VidL models and benchmarks, and draw inspiration from neuroscience and cognitive science to propose avenues for future research in VidL models in particular and artificial intelligence (AI) in general. We argue that iterative feedback loops between AI, neuroscience, and cognitive science are essential to spur progress across these disciplines. We motivate why we focus specifically on VidL models and their benchmarks as a promising type of model to bring improvements in AI and categorise current VidL efforts across multiple'cognitive relevance axioms'. Finally, we provide suggestions on how to effectively incorporate this interdisciplinary viewpoint into research on VidL models in particular and AI in general. In doing so, we hope to create awareness of the potential of VidL models to narrow the gap between neuroscience, cognitive science, and AI.},
    bibtex_show = "",
    preview = "VidLM_Table1.png",
    abbr = "ICCV Workshop",
    selected = "true",
    html = "https://sites.google.com/view/iccv-mmfm/",
}
@article{MURPHY2023154292,
title = {Drug-related causes attributed to acute kidney injury and their documentation in intensive care patients},
journal = {Journal of Critical Care},
volume = {75},
pages = {154292},
year = {2023},
issn = {0883-9441},
doi = {https://doi.org/10.1016/j.jcrc.2023.154292},
url = {https://www.sciencedirect.com/science/article/pii/S0883944123000412},
author = {Rachel M. Murphy and Dave A. Dongelmans and Izak Yasrebi-de Kom and Iacer Calixto and Ameen Abu-Hanna and Kitty J. Jager and Nicolette F. {de Keizer} and Joanna E. Klopotowska},
keywords = {Electronic health records, Acute kidney injury, Nephrotoxicity, Phenotype algorithm, Adverse drug event, Automated identification},
abstract = {Purpose
To investigate drug-related causes attributed to acute kidney injury (DAKI) and their documentation in patients admitted to the Intensive Care Unit (ICU).
Methods
This study was conducted in an academic hospital in the Netherlands by reusing electronic health record (EHR) data of adult ICU admissions between November 2015 to January 2020. First, ICU admissions with acute kidney injury (AKI) stage 2 or 3 were identified. Subsequently, three modes of DAKI documentation in EHR were examined: diagnosis codes (structured data), allergy module (semi-structured data), and clinical notes (unstructured data).
Results
n total 8124 ICU admissions were included, with 542 (6.7%) ICU admissions experiencing AKI stage 2 or 3. The ICU physicians deemed 102 of these AKI cases (18.8%) to be drug-related. These DAKI cases were all documented in the clinical notes (100%), one in allergy module (1%) and none via diagnosis codes. The clinical notes required the highest time investment to analyze.
Conclusions
Drug-related causes comprise a substantial part of AKI in the ICU patients. However, current unstructured DAKI documentation practice via clinical notes hampers our ability to gain better insights about DAKI occurrence. Therefore, both automating DAKI identification from the clinical notes and increasing structured DAKI documentation should be encouraged.},
bibtex_show = "",
preview = "Drug-related_visual-summary.jpg",
selected = "true",
abbr = "Journal of Critical Care",
html = "https://pubmed.ncbi.nlm.nih.gov/36959015/",
}
@InProceedings{10.1007/978-3-031-34344-5_23,
author="Elfrink, Auke
and Vagliano, Iacopo
and Abu-Hanna, Ameen
and Calixto, Iacer",
editor="Juarez, Jose M.
and Marcos, Mar
and Stiglic, Gregor
and Tucker, Allan",
title="Soft-Prompt Tuning to Predict Lung Cancer Using Primary Care Free-Text Dutch Medical Notes",
booktitle="Artificial Intelligence in Medicine",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="193--198",
abstract="We examine the use of large Transformer-based pretrained language models (PLMs) for the problem of early prediction of lung cancer using free-text patient medical notes of Dutch primary care physicians. Specifically, we investigate: 1) how soft prompt-tuning compares to standard model fine-tuning; 2) whether simpler static word embedding models (WEMs) can be more robust compared to PLMs in highly imbalanced settings; and 3) how models fare when trained on notes from a small number of patients. All our code is available open source in https://bitbucket.org/aumc-kik/prompt{\_}tuning{\_}cancer{\_}prediction/.",
isbn="978-3-031-34344-5",
bibtex_show = "",
abbr = "AIME",
html = "https://link.springer.com/chapter/10.1007/978-3-031-34344-5_23",
code = "https://bitbucket.org/aumc-kik/prompt_tuning_cancer_prediction/src/master/",
selected = "true",
preview = "Soft-prompt-tuning_Fig1.png",
}
@inproceedings{raganato-etal-2023-semeval,
    title = "{S}em{E}val-2023 Task 1: Visual Word Sense Disambiguation",
    author = "Raganato, Alessandro  and
      Calixto, Iacer  and
      Ushio, Asahi  and
      Camacho-Collados, Jose  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.semeval-1.308",
    doi = "10.18653/v1/2023.semeval-1.308",
    pages = "2227--2234",
    abstract = "This paper presents the Visual Word Sense Disambiguation (Visual-WSD) task. The objective of Visual-WSD is to identify among a set of ten images the one that corresponds to the intended meaning of a given ambiguous word which is accompanied with minimal context. The task provides datasets for three different languages: English, Italian, and Farsi.We received a total of 96 different submissions. Out of these, 40 systems outperformed a strong zero-shot CLIP-based baseline. Participating systems proposed different zero- and few-shot approaches, often involving generative models and data augmentation. More information can be found on the task{'}s website: {\textbackslash}url{https://raganato.github.io/vwsd/}.",
    bibtex_show = "",
    preview = "Visual-WSD_Figure1.png",
    abbr = "SemEval",
    html = "https://aclanthology.org/2023.semeval-1.308/",
}
@article{cina2023fixing,
  title={Fixing confirmation bias in feature attribution methods via semantic match},
  author={Cin{\`a}, Giovanni and Fernandez-Llaneza, Daniel and Mishra, Nishant and R{\"o}ber, Tabea E and Pezzelle, Sandro and Calixto, Iacer and Goedhart, Rob and Birbil, {\c{S}} {\.I}lker},
  journal={arXiv preprint arXiv:2307.00897},
  year={2023},
  abstract={Feature attribution methods have become a staple method to disentangle the complex behavior of black box models. Despite their success, some scholars have argued that such methods suffer from a serious flaw: they do not allow a reliable interpretation in terms of human concepts. Simply put, visualizing an array of feature contributions is not enough for humans to conclude something about a model's internal representations, and confirmation bias can trick users into false beliefs about model behavior. We argue that a structured approach is required to test whether our hypotheses on the model are confirmed by the feature attributions. This is what we call the "semantic match" between human concepts and (sub-symbolic) explanations. Building on the conceptual framework put forward in Cinà et al. [2023], we propose a structured approach to evaluate semantic match in practice. We showcase the procedure in a suite of experiments spanning tabular and image data, and show how the assessment of semantic match can give insight into both desirable (e.g., focusing on an object relevant for prediction) and undesirable model behaviors (e.g., focusing on a spurious correlation). We couple our experimental results with an analysis on the metrics to measure semantic match, and argue that this approach constitutes the first step towards resolving the issue of confirmation bias in XAI.},
  bibtex_show = "",
abbr = "Pre-print",
arxiv = "2307.00897",
preview = "Semantic-match_Fig3.png",
}
@inproceedings{parcalabescu-etal-2022-valse,
    title = "{VALSE}: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena",
    author = "Parcalabescu, Letitia and
      Cafagna, Michele and
      Muradjan, Lilitta and
      Frank, Anette and
      Calixto, Iacer and
      Gatt, Albert",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.567",
    doi = "10.18653/v1/2022.acl-long.567",
    pages = "8253--8280",
    abstract = "We propose VALSE (Vision And Language Structured Evaluation), a novel benchmark designed for testing general-purpose pretrained vision and language (V{\&}L) models for their visio-linguistic grounding capabilities on specific linguistic phenomena. VALSE offers a suite of six tests covering various linguistic constructs. Solving these requires models to ground linguistic phenomena in the visual modality, allowing more fine-grained evaluations than hitherto possible. We build VALSE using methods that support the construction of valid foils, and report results from evaluating five widely-used V{\&}L models. Our experiments suggest that current models have considerable difficulty addressing most phenomena. Hence, we expect VALSE to serve as an important benchmark to measure future progress of pretrained V{\&}L models from a linguistic perspective, complementing the canonical task-centred V{\&}L evaluations.",
    bibtex_show = "",
    abbr = "ACL",
    html = "https://aclanthology.org/2022.acl-long.567/",
    code = "https://github.com/heidelberg-nlp/valse",
    preview = "VALSE_Table1.png",
}
